{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1 - Q4 (2)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3T9/wPQjbGfXH9Ho8Mqwo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanchitkalra/bits-f312-nnfl/blob/main/Assignment_1_Q4_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hoSOPV3po_6L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openpyxl==3.0.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Igl4SnmpILC",
        "outputId": "40074d35-8232-49fa-b3b2-0c76ed970bb3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl==3.0.9 in /usr/local/lib/python3.7/dist-packages (3.0.9)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl==3.0.9) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUTxCAGLpIxj",
        "outputId": "9971962e-3e14-4646-acb0-e831cfcc3386"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the data from Google Drive**"
      ],
      "metadata": {
        "id": "96XS2BpTteq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/drive/MyDrive/data.xlsx',header=None)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIl5tmRjpLDt",
        "outputId": "d632ae05-951c-4f0e-882c-5f05a6e02762"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              0           1           2   ...        58        59  60\n",
            "0     242.751526  281.801298  250.032405  ...  1.281972  1.844860   1\n",
            "1     216.585951  297.057883  300.938478  ...  1.598582  1.625395   1\n",
            "2     265.735536  339.271134  269.817305  ...  1.848160  1.706134   1\n",
            "3     207.631953  255.284282  254.563071  ...  1.710404  1.664391   1\n",
            "4     205.016124  333.265999  536.342842  ...  1.703264  1.535684   1\n",
            "...          ...         ...         ...  ...       ...       ...  ..\n",
            "3407  723.913528  343.529660  360.468834  ...  1.948758  1.758541   4\n",
            "3408  466.593370  215.858228  235.940729  ...  1.568558  1.494537   4\n",
            "3409  446.227198  219.936910  181.605753  ...  1.418510  1.772295   4\n",
            "3410  511.406437  215.379710  170.598957  ...  1.609298  1.664890   4\n",
            "3411  757.967516  268.431243  189.755280  ...  1.790039  1.560633   4\n",
            "\n",
            "[3412 rows x 61 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "datan = data.values\n",
        "\n",
        "X = datan[:, 0:60]\n",
        "m = X.shape[0]\n",
        "print(m)\n",
        "\n",
        "\n",
        "# Normalise X\n",
        "xmin = np.min(X, axis = 0)\n",
        "xmax = np.max(X, axis = 0)\n",
        "X = (X-xmin)/(xmax - xmin)\n",
        "print(X.shape)\n",
        "\n",
        "# Normalise Y\n",
        "y=datan[:, 60]\n",
        "y = y - 1\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHmYuK1QpNpr",
        "outputId": "a4365d17-6814-4ac2-c63c-98ebcf60c98e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3412\n",
            "(3412, 60)\n",
            "(3412,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining the requisite functions**\n",
        "\n",
        "Each function has a l2 parameter that allows us to choose between L1 and L2 norm regularisation with this flag. If the value of lambda is 0, there is no regularisation irrespective of the flag value"
      ],
      "metadata": {
        "id": "2JKlGGZwtW4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0/(1 + np.exp(-z)) ###activation function"
      ],
      "metadata": {
        "id": "FACZvbwDpP7p"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(X,y,w, lamb, l2 = True): \n",
        "    hypothesis = sigmoid(np.dot(X,w.T)) \n",
        "    if l2:\n",
        "        J =-(1/m)*(np.sum(y*(np.log(hypothesis)) + (1-y)*np.log(1-hypothesis))) + (lamb/2)*np.sum(np.abs(w)**2) \n",
        "    else:\n",
        "        J =-(1/m)*(np.sum(y*(np.log(hypothesis)) + (1-y)*np.log(1-hypothesis))) + (lamb/2)*np.sum(np.abs(w)) \n",
        "    return J"
      ],
      "metadata": {
        "id": "Nuyx1LJTpRSt"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_gradient_descent(X,y,w,alpha,iters, lamb, l2 = True):\n",
        "    cost_history = np.zeros(iters) \n",
        "    for i in range(iters):\n",
        "        hypothesis = sigmoid(np.dot(X,w.T))\n",
        "        if l2:\n",
        "            w = w - (alpha/len(y)) * np.dot(hypothesis - y, X) - (alpha*lamb)*w\n",
        "        else:\n",
        "            w = w - (alpha/len(y)) * np.dot(hypothesis - y, X) - ((alpha*lamb)/2)*np.sign(w)\n",
        "        cost_history[i] = cost_function(X,y,w, lamb)\n",
        "    return w,cost_history"
      ],
      "metadata": {
        "id": "O7me-URJpS1D"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MB_gradient_descent(X,y,w,alpha, iters, batch_size, lamb, l2 = True):\n",
        "    cost_history = np.zeros(iters)\n",
        "    for i in range(iters):\n",
        "        rand_index = np.random.randint(len(y)-batch_size)\n",
        "        ind_x = X[rand_index:rand_index+batch_size]\n",
        "        ind_y = y[rand_index:rand_index+batch_size]\n",
        "        if l2:\n",
        "            w = w - (alpha/batch_size) * (ind_x.T.dot(sigmoid(ind_x.dot(w)) - ind_y)) - (alpha*lamb)*w\n",
        "        else:\n",
        "            w = w - (alpha/batch_size) * (ind_x.T.dot(sigmoid(ind_x.dot(w)) - ind_y)) - ((alpha*lamb)/2)*np.sign(w)\n",
        "        cost_history[i] = cost_function(ind_x,ind_y,w, lamb)\n",
        "    return w, cost_history"
      ],
      "metadata": {
        "id": "HPcAFE35pWHn"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stochastic_gradient_descent(X,y,w,alpha, iters, lamb, l2 = True):\n",
        "    cost_history = np.zeros(iters)\n",
        "    for i in range(iters):\n",
        "        rand_index = np.random.randint(len(y)-1)\n",
        "        ind_x = X[rand_index:rand_index+1]\n",
        "        ind_y = y[rand_index:rand_index+1]\n",
        "        if l2:\n",
        "            w = w - alpha * (ind_x.T.dot(sigmoid(ind_x.dot(w)) - ind_y)) - (alpha*lamb)*w\n",
        "        else:\n",
        "            w = w - alpha * (ind_x.T.dot(sigmoid(ind_x.dot(w)) - ind_y)) - ((alpha*lamb)/2)*np.sign(w)\n",
        "        cost_history[i] = cost_function(ind_x,ind_y,w, lamb)\n",
        "    return w, cost_history"
      ],
      "metadata": {
        "id": "N7oapBGkpXVA"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Holdout Validation\n",
        "Splitting the data into 3 sets, 70% training, 20% test and 10% validation"
      ],
      "metadata": {
        "id": "aU7NRbZDuF5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.3)\n",
        "print(x_train.shape)\n",
        "print(x_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EIIclAHpZlq",
        "outputId": "c6ce1b24-9a02-4ce1-c936-2988a2e91d69"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2388, 60)\n",
            "(1024, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, x_val, y_test, y_val = train_test_split(x_test1, y_test1, test_size=0.33)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eakMmVC1pa6d",
        "outputId": "45cde2ee-1a04-4f91-c92f-017a6ca92c79"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(686, 60)\n",
            "(338, 60)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda x: 1 if(x == 0) else 0"
      ],
      "metadata": {
        "id": "WiY-7CPApcM0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squares = np.array([f(x) for x in y_train])"
      ],
      "metadata": {
        "id": "APdtgvTZpeDg"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperating the data into 4 sets.\n",
        "# Each set has the value corresponding to k set to 1 and the rest 0.\n",
        "\n",
        "cases = []\n",
        "cases_t = []\n",
        "\n",
        "for k in range(4):\n",
        "  f = lambda x: 1 if(x == k) else 0\n",
        "  y_tr = np.array([f(x) for x in y_train])\n",
        "  y_te = np.array([f(x) for x in y_test])\n",
        "  print(y_tr)\n",
        "  cases.append(y_tr)\n",
        "  cases_t.append(y_te)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CMkkQZFpkYj",
        "outputId": "e7335de4-5eda-41e6-96b0-b34ffedc6b24"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 0 0 0]\n",
            "[0 0 0 ... 1 0 0]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[0 0 0 ... 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the required weights\n",
        "# The four different weights for the four different models required by the One-vs-All classifier\n",
        "\n",
        "def prep():\n",
        "    weights = []\n",
        "    for k in range(4):\n",
        "        weights.append(np.random.randn(1,X.shape[1]).ravel())\n",
        "        \n",
        "    return weights"
      ],
      "metadata": {
        "id": "c61KF1E6plrJ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the actual training function\n",
        "def train(weights, cases, alpha, iters, lamb, batch_size, func, l2 = True):\n",
        "    for k in range(len(cases)):\n",
        "        if func == MB_gradient_descent:\n",
        "            calc_w,J_his = func(x_train, cases[k], weights[k], alpha, iters, batch_size, lamb, l2)\n",
        "        else:\n",
        "            calc_w,J_his = func(x_train, cases[k], weights[k], alpha, iters, lamb, l2)\n",
        "        weights[k] = calc_w\n",
        "    return (weights, J_his)"
      ],
      "metadata": {
        "id": "5f4HTi1Gpmw5"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_plot(iters, J_his):\n",
        "    plt.plot(range(iters),J_his)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HFhxaSOqpoB1"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pred(weights):\n",
        "    Y_Pred = []\n",
        "    for k in range(len(weights)):\n",
        "        z = np.dot(x_val, weights[k].T)\n",
        "        h = sigmoid(z)\n",
        "        y_pred=h>0.5\n",
        "        y_pred=y_pred.astype(int)\n",
        "        Y_Pred.append(y_pred)\n",
        "    return Y_Pred"
      ],
      "metadata": {
        "id": "K-eTFSSFppJ1"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(Y_Pred):\n",
        "    Y_Pred = np.array(Y_Pred).T\n",
        "    max = np.argmax(Y_Pred, axis=1)\n",
        "    cm=confusion_matrix(y_val, max)\n",
        "    accuracy=(cm[0][0]+cm[1][1])/(len(y_val))\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Ymd229OJpqYE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_functions_and_reg(alpha, iters, lamb, batch_size, show_plots):\n",
        "    for func in [batch_gradient_descent, MB_gradient_descent, stochastic_gradient_descent]: # three algos\n",
        "        for j in range(3): # 3 kinds of regularisation\n",
        "            accuracy = 0\n",
        "            if j == 0: ## no regularisation\n",
        "                lamb = 0\n",
        "                weights = prep()\n",
        "                training_output = train(weights, cases, alpha, iters, lamb, batch_size, func, l2 = True)\n",
        "                Y_Pred = make_pred(training_output[0])\n",
        "                accuracy = get_accuracy(Y_Pred)\n",
        "                if show_plots:\n",
        "                    show_plot(iters, training_output[1])\n",
        "                print(\"Accuracy \" + str(accuracy) + \" with \" + str(func) + \" at alpha \" + str(alpha) + \" at iters \" + str(iters) + \" at lamb \" + str(lamb))\n",
        "            elif j == 1: ## l2 reg\n",
        "                weights = prep()\n",
        "                training_output = train(weights, cases, alpha, iters, lamb, batch_size, func, l2 = True)\n",
        "                Y_Pred = make_pred(training_output[0])\n",
        "                if show_plots:\n",
        "                    show_plot(iters, training_output[1])\n",
        "                print(\"Accuracy \" + str(accuracy) + \" with \" + str(func) + \" and L2 at alpha \" + str(alpha) + \" at iters \" + str(iters) + \" at lamb \" + str(lamb))\n",
        "            else: ## l1 reg\n",
        "                weights = prep()\n",
        "                training_output = train(weights, cases, alpha, iters, lamb, batch_size, func, l2 = False)\n",
        "                Y_Pred = make_pred(training_output[0])\n",
        "                if show_plots:\n",
        "                    show_plot(iters, training_output[1])\n",
        "                print(\"Accuracy \" + str(accuracy) + \" with \" + str(func) + \" and L1 at alpha \" + str(alpha) + \" at iters \" + str(iters) + \" at lamb \" + str(lamb))\n",
        "\n",
        "            return (accuracy, alpha, iters, lamb, batch_size, func)"
      ],
      "metadata": {
        "id": "XTh3iheSprgC"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, we run 2,025 combinations to find the optimal value for the parameters: alpha, lambda, iterations, and batch size"
      ],
      "metadata": {
        "id": "Na_dv8IPvR6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas=[0.01, 0.02, 0.05] ##learning rate\n",
        "iterss=[2000, 5000, 10000] ###iterations\n",
        "lambs = [0.1, 0.2, 0.5]\n",
        "batch_sizes = [500, 1000, 1500]\n",
        "\n",
        "current_accuracy = 0\n",
        "current_alpha = 0\n",
        "current_iters = 0\n",
        "current_lamb = 0\n",
        "current_batch_size = 0\n",
        "current_algo = \"\"\n",
        "\n",
        "for alpha in alphas:\n",
        "    for iters in iterss:\n",
        "        for lamb in lambs:\n",
        "            for batch_size in batch_sizes:\n",
        "                # (r_accuracy, r_alpha, r_iters, r_lamb, r_batch_size)\n",
        "                output = run_all_functions_and_reg(alpha, iters, lamb, batch_size, False)\n",
        "                if output[0] >= current_accuracy:\n",
        "                  current_accuracy = output[0]\n",
        "                  current_alpha = output[1]\n",
        "                  current_iters = output[2]\n",
        "                  current_lamb = output[3]\n",
        "                  current_batch_size = output[4]\n",
        "                  current_algo = str(output[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "EF3IQnbWptPt",
        "outputId": "8c903949-282f-48ce-e98c-5b9885350d04"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.257396449704142 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.26627218934911245 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.26627218934911245 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.26331360946745563 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.29289940828402367 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.257396449704142 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.26627218934911245 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.27218934911242604 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.26331360946745563 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 2000 at lamb 0\n",
            "Accuracy 0.27218934911242604 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.27514792899408286 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.28994082840236685 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.28994082840236685 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.2781065088757396 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.27514792899408286 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.2692307692307692 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.2692307692307692 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.28402366863905326 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 5000 at lamb 0\n",
            "Accuracy 0.29289940828402367 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 10000 at lamb 0\n",
            "Accuracy 0.27514792899408286 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 10000 at lamb 0\n",
            "Accuracy 0.2869822485207101 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 10000 at lamb 0\n",
            "Accuracy 0.29289940828402367 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 10000 at lamb 0\n",
            "Accuracy 0.28994082840236685 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 10000 at lamb 0\n",
            "Accuracy 0.28994082840236685 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 10000 at lamb 0\n",
            "Accuracy 0.29289940828402367 with <function batch_gradient_descent at 0x7ff5c84cd440> at alpha 0.01 at iters 10000 at lamb 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-e30174131288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;31m# (r_accuracy, r_alpha, r_iters, r_lamb, r_batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_all_functions_and_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcurrent_accuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                   \u001b[0mcurrent_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-2220ad7d4850>\u001b[0m in \u001b[0;36mrun_all_functions_and_reg\u001b[0;34m(alpha, iters, lamb, batch_size, show_plots)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mlamb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0mtraining_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mY_Pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_Pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-4144c9880228>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(weights, cases, alpha, iters, lamb, batch_size, func, l2)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mcalc_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJ_his\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mcalc_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJ_his\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ_his\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-57-0273cefccfa5>\u001b[0m in \u001b[0;36mbatch_gradient_descent\u001b[0;34m(X, y, w, alpha, iters, lamb, l2)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **One-vs-One Classification**"
      ],
      "metadata": {
        "id": "Gr0nLUNntDGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First let's read the input data again\n",
        "data = pd.read_excel('/content/drive/MyDrive/data.xlsx',header=None)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "-IODqi80tJFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datan = data.values"
      ],
      "metadata": {
        "id": "Z363wrHJy16E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We now need 4C2 since there are 4 classes and one-vs-one needs combinations of two classes at a time\n",
        "\n",
        "arrays = [] # we will store the 6 arrays in this list\n",
        "combinations = []\n",
        "\n",
        "# possible classes\n",
        "a_list = [0, 1, 2, 3] \n",
        "\n",
        "# array of all possible combinations\n",
        "import itertools\n",
        "all_combinations = []\n",
        "for r in [2]:\n",
        "    combinations_object = itertools.combinations(a_list, r)\n",
        "    combinations_list = list(combinations_object)\n",
        "    all_combinations += combinations_list\n",
        "\n",
        "print(all_combinations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p75xL_9zEsN",
        "outputId": "53f63547-05ef-4ea0-9469-80485ac5739d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = datan[:, 0:60]\n",
        "filter_arr = np.array()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "lBD5dbp-0jvv",
        "outputId": "a9c9b782-70a8-448c-8b58-64a84681c071"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-702607b342b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilter_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: array() missing required argument 'object' (pos 0)"
          ]
        }
      ]
    }
  ]
}